---
weight_dir: c2cs/c2cs_img # path to folder where checkpoints should be stored
# name_load: c2cs_log-80000

common:
  unpin: false # disable pinning for the loader
  batch_size: 1
  num_loaders: 16
  log_interval: 1 # print losses every X iterations
  seed: 1

train:
  max_epochs: -1
  max_iterations: 1000000
  save_epochs: -1 # save every X epochs
  save_iterations: 20000 # save every X iterations
  name_save: c2cs_img
  shuffle_train: true
  val_interval: 50 # run inference on validation set every X iterations
   
test:
  shuffle_test: false

real_dataset:
  name: cityscapes
  filelist: data/cityscapes/cityscapes_files.txt # file with path to image in each line.

fake_dataset: 
  name: hddCARLA
  train_filelist: data/hddCARLA/train.txt # file with paths to image, gbuffers, robust labels, and gt labels (for deriving material segmentation) in each line.
  val_filelist: data/hddCARLA/val.txt # see above
  test_filelist: data/hddCARLA/test.txt # see above
  sampling: 
    type: 'matching'
    matched_crop_path: data/matches/matched_crops_hddCARLA-cityscapes.csv # generated by matching/filter.py
    crop_weight_path: data/matches/crop_weights_hddCARLA-cityscapes.npz # generated by matching/compute_weights.py

generator:
  type: hr_new
  config:
    encoder_type: ENCODER
    stem_norm: group
    num_stages: 6 # 4
    other_norm: group
    gbuffer_norm: RAC # RAD
    gbuffer_encoder_norm: residual2
    num_gbuffer_layers: 3
  optimizer:
    type: adam
    learning_rate: 0.0001
    adam_beta: 0.9
    adam_beta2: 0.999
    clip_gradient_norm: 1000
  scheduler:
    type: 'step'
    step: 100000
    gamma: 0.5
    
discriminator:
  type: ppde
  run_always: false
  config:
    norm: group
    num_layers: 4
    max_dim: 256
  optimizer:
    type: adam
    learning_rate: 0.0001 
    adam_beta: 0.9
    adam_beta2: 0.999
    clip_gradient_norm: 1000
  scheduler:
    type: 'step'
    step: 1000000
    gamma: 0.5
    
objectives:
  gan: ls
  perceptual:
    type: 'lpips_vgg'
    weight: 1
  reg:
    weight: 0.03
...
