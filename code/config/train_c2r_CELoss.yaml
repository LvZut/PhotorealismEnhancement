---
weight_dir: c2r/c2r_CELoss_01 # path to folder where checkpoints should be stored
name_load: c2r_CELoss_01-110000

common:
  unpin: false # disable pinning for the loader
  batch_size: 1
  num_loaders: 0 #16
  log_interval: 1 # print losses every X iterations
  seed: 1

train:
  max_epochs: -1
  max_iterations: 1000000
  save_epochs: -1 # save every X epochs
  save_iterations: 10000 # save every X iterations
  name_save: c2r_CELoss
  shuffle_train: true
  val_interval: 5000 # run inference on validation set every X iterations
  no_validation: False # prevents val dataloader from loading in, also prevents tensorboard preview images
   
test:
  shuffle_test: false

real_dataset:
  name: real
  filelist: data/real/real_files.txt # file with path to image in each line.

fake_dataset: 
  name: CARLA
  train_filelist: data/CARLA/train.txt # file with paths to image, gbuffers, robust labels, and gt labels (for deriving material segmentation) in each line.
  val_filelist: data/CARLA/val.txt # see above
  test_filelist: data/CARLA/test.txt # see above
  sampling: 
    type: 'matching'
    matched_crop_path: data/matches/matched_crops_CARLA-real.csv # generated by matching/filter.py
    crop_weight_path: data/matches/crop_weights_CARLA-real.npz # generated by matching/compute_weights.py
    crop_size: 196

generator:
  type: hr_new #hr
  config:
    encoder_type: ENCODER
    stem_norm: group
    num_stages: 6 #6
    other_norm: group
    gbuffer_norm: RAC # RAD
    gbuffer_encoder_norm: residual2 # residual
    num_gbuffer_layers: 3 #3
  optimizer:
    type: adam
    learning_rate: 0.00005
    adam_beta: 0.9
    adam_beta2: 0.999
    clip_gradient_norm: 1000
  scheduler:
    type: 'step'
    step: 100000
    gamma: 0.5
    
discriminator:
  type: ppde
  run_always: false
  config:
    norm: group
    num_layers: 4 #4
    max_dim: 256
  optimizer:
    type: adam
    learning_rate: 0.00005 
    adam_beta: 0.9
    adam_beta2: 0.999
    clip_gradient_norm: 1000
  scheduler:
    type: 'step'
    step: 1000000
    gamma: 0.5

objectives:
  gan: ls
  perceptual:
    vgg_input: robust # rgb, robust
    type: 'CELoss' # lpips_vgg, MSE
    weight: 0.1
    vgg_decay: 1
  reg:
    weight: 0.03
...

